{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare evaluation and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we have prepared the training dataset. Now we will conduct the same preprocessing steps to make the evaluation and test datasets ready. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source of the data for evaluation and test datasets is the competition dataset that can be found here:\n",
    "<p>round2_competition_data/<br>\n",
    "&ensp;&ensp;&ensp;&ensp; ├── round2_competition.csv<br>\n",
    "&ensp;&ensp;&ensp;&ensp; ├── round2_sensors.csv <br>\n",
    "\n",
    "The evaluation and test datasets are going to be saved in a single file called <i>eval_test.csv</i>. Before evaluating the machine learning model, we will specify the proportion of the dataset to include either in the evaluation and test splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin with importing all libraries that will be used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import SparkSession\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate the <i>SparkSession</i>. For testing, the application will be running locally with 2 cores, and 4 GB of memory for the driver process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"ads-b data processing\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of output partitions\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 100)\n",
    "\n",
    "# Set log level\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will load the CSV file and print its schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "    .options(header='True', inferSchema='True') \\\n",
    "    .load(\"round2_competition_data/round2_competition.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- timeAtServer: double (nullable = true)\n",
      " |-- aircraft: integer (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- baroAltitude: double (nullable = true)\n",
      " |-- geoAltitude: double (nullable = true)\n",
      " |-- numMeasurements: integer (nullable = true)\n",
      " |-- measurements: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode the measurements data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to do the following:\n",
    "- explode the measurements JSON array, sort it according to sensor serial number and limit the number of measurements\n",
    "- extract the sensor, timestamp and RSSI information from array of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.limit(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_measurements = 6\n",
    "json_schema = types.ArrayType(types.ArrayType(types.DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('meas', F.from_json('measurements', schema=json_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort arrays of measurements according to sensor's serial number\n",
    "df = df.rdd.map(lambda x: [x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7], x[8], \\\n",
    "                           sorted(x[9], key=operator.itemgetter(0), reverse=False)]) \\\n",
    "                                .toDF(df.schema.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|        measurements|                meas|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|[[208,962354640,9...|[[197.0, 5.770127...|\n",
      "|  2|[[150,968341093,8...|[[150.0, 9.683410...|\n",
      "|  3|[[470,982753933,3...|[[470.0, 9.827539...|\n",
      "|  4|[[203,79215063833...|[[23.0, 6.1095513...|\n",
      "|  5|[[203,79216918750...|[[203.0, 7.921691...|\n",
      "|  6|[[150,971816968,8...|[[150.0, 9.718169...|\n",
      "|  7|[[166,33743812166...|[[26.0, -5.1503E8...|\n",
      "|  8|[[625,-1965785000...|[[215.0, 4.459894...|\n",
      "|  9|[[607,26027857583...|[[461.0, 2.740584...|\n",
      "| 10|[[166,33767674666...|[[166.0, 3.376767...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('id', 'measurements', 'meas').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['sensor', 'tmp', 'RSSI']\n",
    "col_types = ['int', 'Decimal(16,0)', 'int']\n",
    "\n",
    "for i in range(max_measurements):\n",
    "    for j, col_name in enumerate(col_names): \n",
    "        df = df.withColumn('{}_{}'.format(col_name, i), F.col('meas')[i][j].cast(col_types[j]))\n",
    "\n",
    "df = df.drop('meas', 'measurements') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----------+------+--------+-----------+------+\n",
      "|id |sensor_0|tmp_0      |RSSI_0|sensor_1|tmp_1      |RSSI_1|\n",
      "+---+--------+-----------+------+--------+-----------+------+\n",
      "|1  |197     |5770127167 |109   |208     |962354640  |98    |\n",
      "|2  |150     |968341093  |82    |434     |3229609750 |63    |\n",
      "|3  |470     |982753933  |38    |499     |6026974083 |30    |\n",
      "|4  |23      |61095513667|190   |134     |940042921  |62    |\n",
      "|5  |203     |79216918750|8     |315     |31656195917|154   |\n",
      "|6  |150     |971816968  |80    |434     |3233068917 |177   |\n",
      "|7  |26      |-515030000 |219   |166     |33743812167|78    |\n",
      "|8  |215     |44598943167|94    |352     |22189829750|65    |\n",
      "|9  |461     |2740584833 |20    |607     |26027857583|62    |\n",
      "|10 |166     |33767674667|32    |346     |65133682333|29    |\n",
      "+---+--------+-----------+------+--------+-----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('id', 'sensor_0', 'tmp_0', 'RSSI_0', 'sensor_1', 'tmp_1', 'RSSI_1').show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.save('round2_competition_data/eval_test', format='csv', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [name for name in os.listdir('round2_competition_data/eval_test') if name.startswith('part')]\n",
    "\n",
    "os.rename(os.path.join('round2_competition_data/eval_test', file_name[0]),\n",
    "          'round2_competition_data/eval_test/eval_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data casting and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will cast the data to proper data types and filter-out data with incorrect timestamps or without coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('round2_competition_data/eval_test/eval_test.csv')\n",
    "\n",
    "max_measurements = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'id': 'int32', 'timeAtServer': 'float32', 'aircraft': 'int16', 'latitude': 'float32', 'longitude': 'float32',\n",
    "        'baroAltitude': 'float32', 'geoAltitude': 'float32', 'numMeasurements': 'int16'}\n",
    "\n",
    "for i in range(max_measurements):\n",
    "    types['tmp_{}'.format(i)] = 'float64'\n",
    "    types['RSSI_{}'.format(i)] = 'int16'\n",
    "    \n",
    "flights.fillna(value={i:0 for i in list(types.keys()) if i.startswith('RSSI')}, inplace=True)\n",
    "\n",
    "flights = flights.astype(types, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['tmp_0'] = flights['tmp_0'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "\n",
    "for i in range(max_measurements):\n",
    "    idx.extend(flights.loc[flights['tmp_{}'.format(i)] == 0].index)\n",
    "        \n",
    "flights.drop(idx, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some data points that don't contain aircraft coordinates. Those localizations should be predicted using our model, thus we can remove them from our evaluation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without aircraft localization:  632932\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows without aircraft localization: ', len(flights.loc[flights.latitude.isna(), 'latitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.dropna(subset=['latitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset:  5824608\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows in dataset: ', len(flights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.to_csv('round2_competition_data/eval_test/eval_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform timestamp synchronization in evaluation and test datasets, we have to load the coefficient dictionary of linear regression models created in the previous notebook. The correction coefficients enable us to estimate the value of timestamp correction that needs to be applied at a given time and for a specific pair of sensors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_measurements = 6\n",
    "\n",
    "types = {'id': 'int32', 'timeAtServer': 'float32', 'aircraft': 'int16', 'latitude': 'float32', 'longitude': 'float32',\n",
    "        'baroAltitude': 'float32', 'geoAltitude': 'float32', 'numMeasurements': 'int16'}\n",
    "\n",
    "for i in range(max_measurements):\n",
    "    types['tmp_{}'.format(i)] = 'float64'\n",
    "    types['RSSI_{}'.format(i)] = 'int16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('round2_competition_data/eval_test/eval_test.csv', dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = pd.read_csv('round2_training/round2/round2_sensors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"coeff_dict.pickle\", \"rb\") as output_file:\n",
    "    coeff_dict = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will join the flights' dataset with the sensors' dataframe in order to extract receivers coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors.set_index('serial', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_measurements):\n",
    "    flights = flights.join(sensors.loc[:, ['latitude', 'longitude', 'height']], on='sensor_{}'.format(i),\n",
    "                           rsuffix='_{}'.format(i))\n",
    "    \n",
    "flights.rename({'height': 'height_0'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_coords = {}\n",
    "\n",
    "for i in range(max_measurements):\n",
    "    types_coords['latitude_{}'.format(i)] = 'float32'\n",
    "    types_coords['longitude_{}'.format(i)] = 'float32'\n",
    "    types_coords['height_{}'.format(i)] = 'float32'\n",
    "    \n",
    "flights = flights.astype(types_coords, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>tmp_0</th>\n",
       "      <th>tmp_1</th>\n",
       "      <th>tmp_2</th>\n",
       "      <th>tmp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197</td>\n",
       "      <td>208</td>\n",
       "      <td>5.770127e+09</td>\n",
       "      <td>9.623546e+08</td>\n",
       "      <td>3.714525e+10</td>\n",
       "      <td>1.712590e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>434</td>\n",
       "      <td>9.683411e+08</td>\n",
       "      <td>3.229610e+09</td>\n",
       "      <td>2.913790e+10</td>\n",
       "      <td>2.683911e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "      <td>499</td>\n",
       "      <td>9.827539e+08</td>\n",
       "      <td>6.026974e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>134</td>\n",
       "      <td>6.109551e+10</td>\n",
       "      <td>9.400429e+08</td>\n",
       "      <td>4.906758e+10</td>\n",
       "      <td>-1.446033e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>315</td>\n",
       "      <td>7.921692e+10</td>\n",
       "      <td>3.165620e+10</td>\n",
       "      <td>6.728977e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>434</td>\n",
       "      <td>9.718170e+08</td>\n",
       "      <td>3.233069e+09</td>\n",
       "      <td>2.914142e+10</td>\n",
       "      <td>2.684295e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>5.150300e+08</td>\n",
       "      <td>3.374381e+10</td>\n",
       "      <td>3.892270e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>215</td>\n",
       "      <td>352</td>\n",
       "      <td>4.459894e+10</td>\n",
       "      <td>2.218983e+10</td>\n",
       "      <td>-1.965785e+09</td>\n",
       "      <td>5.946908e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>461</td>\n",
       "      <td>607</td>\n",
       "      <td>2.740585e+09</td>\n",
       "      <td>2.602786e+10</td>\n",
       "      <td>2.452693e+10</td>\n",
       "      <td>4.596197e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>3.376767e+10</td>\n",
       "      <td>6.513368e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>4.842533e+08</td>\n",
       "      <td>3.377384e+10</td>\n",
       "      <td>3.895347e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sensor_0  sensor_1         tmp_0         tmp_1         tmp_2         tmp_3\n",
       "0        197       208  5.770127e+09  9.623546e+08  3.714525e+10  1.712590e+10\n",
       "1        150       434  9.683411e+08  3.229610e+09  2.913790e+10  2.683911e+10\n",
       "2        470       499  9.827539e+08  6.026974e+09           NaN           NaN\n",
       "3         23       134  6.109551e+10  9.400429e+08  4.906758e+10 -1.446033e+08\n",
       "4        203       315  7.921692e+10  3.165620e+10  6.728977e+10           NaN\n",
       "5        150       434  9.718170e+08  3.233069e+09  2.914142e+10  2.684295e+10\n",
       "6         26       166  5.150300e+08  3.374381e+10  3.892270e+10           NaN\n",
       "7        215       352  4.459894e+10  2.218983e+10 -1.965785e+09  5.946908e+10\n",
       "8        461       607  2.740585e+09  2.602786e+10  2.452693e+10  4.596197e+10\n",
       "9        166       346  3.376767e+10  6.513368e+10           NaN           NaN\n",
       "10        26       166  4.842533e+08  3.377384e+10  3.895347e+10           NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.loc[:10, ['sensor_0', 'sensor_1', 'tmp_0', 'tmp_1', 'tmp_2', 'tmp_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will begin the timestamp synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 5824608/5824608 [02:27<00:00, 39621.83it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected_tmp = {}\n",
    "\n",
    "for row in tqdm(flights.itertuples(), total=len(flights)):\n",
    "    \n",
    "    s1 = row.sensor_0\n",
    "    timeAtServer = row.timeAtServer\n",
    "    \n",
    "    for i in range(1, max_measurements):\n",
    "        \n",
    "        corrected_tmp.setdefault(i, [])\n",
    "        \n",
    "        s2 = getattr(row, 'sensor_{}'.format(i))\n",
    "        tmp_2 = getattr(row, 'tmp_{}'.format(i))\n",
    "        \n",
    "        if np.isnan(tmp_2):\n",
    "            corrected_tmp[i].append(np.NaN)\n",
    "            continue\n",
    "        \n",
    "        # Return the correction coefficients (default=(0,0))\n",
    "        m, b = coeff_dict.get('{}_{}'.format(int(s1), int(s2)), (0, 0))\n",
    "        \n",
    "        corr = m * timeAtServer + b\n",
    "        \n",
    "        corrected_tmp[i].append(tmp_2 - corr)      \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, max_measurements):\n",
    "    flights['tmp_{}'.format(i)] = pd.Series(corrected_tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>tmp_0</th>\n",
       "      <th>tmp_1</th>\n",
       "      <th>tmp_2</th>\n",
       "      <th>tmp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197</td>\n",
       "      <td>208</td>\n",
       "      <td>5.770127e+09</td>\n",
       "      <td>2.662732e+10</td>\n",
       "      <td>5.770716e+09</td>\n",
       "      <td>5.771402e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>434</td>\n",
       "      <td>9.683411e+08</td>\n",
       "      <td>-1.988912e+10</td>\n",
       "      <td>-1.989066e+10</td>\n",
       "      <td>-1.988808e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "      <td>499</td>\n",
       "      <td>9.827539e+08</td>\n",
       "      <td>-1.988008e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>134</td>\n",
       "      <td>6.109551e+10</td>\n",
       "      <td>8.225027e+10</td>\n",
       "      <td>6.140679e+10</td>\n",
       "      <td>6.139881e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>315</td>\n",
       "      <td>7.921692e+10</td>\n",
       "      <td>-1.045893e+10</td>\n",
       "      <td>7.908962e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>434</td>\n",
       "      <td>9.718170e+08</td>\n",
       "      <td>-1.988566e+10</td>\n",
       "      <td>-1.988714e+10</td>\n",
       "      <td>-1.988424e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>5.150300e+08</td>\n",
       "      <td>-5.230030e+08</td>\n",
       "      <td>-5.246905e+08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>215</td>\n",
       "      <td>352</td>\n",
       "      <td>4.459894e+10</td>\n",
       "      <td>4.458725e+10</td>\n",
       "      <td>4.459669e+10</td>\n",
       "      <td>4.459535e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>461</td>\n",
       "      <td>607</td>\n",
       "      <td>2.740585e+09</td>\n",
       "      <td>3.700265e+09</td>\n",
       "      <td>3.508737e+09</td>\n",
       "      <td>3.509040e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>3.376767e+10</td>\n",
       "      <td>1.303481e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>4.842533e+08</td>\n",
       "      <td>-4.929767e+08</td>\n",
       "      <td>-4.939229e+08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sensor_0  sensor_1         tmp_0         tmp_1         tmp_2         tmp_3\n",
       "0        197       208  5.770127e+09  2.662732e+10  5.770716e+09  5.771402e+09\n",
       "1        150       434  9.683411e+08 -1.988912e+10 -1.989066e+10 -1.988808e+10\n",
       "2        470       499  9.827539e+08 -1.988008e+10           NaN           NaN\n",
       "3         23       134  6.109551e+10  8.225027e+10  6.140679e+10  6.139881e+10\n",
       "4        203       315  7.921692e+10 -1.045893e+10  7.908962e+10           NaN\n",
       "5        150       434  9.718170e+08 -1.988566e+10 -1.988714e+10 -1.988424e+10\n",
       "6         26       166  5.150300e+08 -5.230030e+08 -5.246905e+08           NaN\n",
       "7        215       352  4.459894e+10  4.458725e+10  4.459669e+10  4.459535e+10\n",
       "8        461       607  2.740585e+09  3.700265e+09  3.508737e+09  3.509040e+09\n",
       "9        166       346  3.376767e+10  1.303481e+11           NaN           NaN\n",
       "10        26       166  4.842533e+08 -4.929767e+08 -4.939229e+08           NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.loc[:10, ['sensor_0', 'sensor_1', 'tmp_0', 'tmp_1', 'tmp_2', 'tmp_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronized data can be saved into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.to_csv('round2_competition_data/eval_test/eval_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to focus on extracting the following additional features:\n",
    "- timestamp differences\n",
    "- the mean latitude and longitude location of the receivers\n",
    "- the weighted mean of sensors coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we will instantiate the <i>SparkSession</i> and set the number of output partitions and the log level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"ads-b data processing\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of output partitions\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 100)\n",
    "\n",
    "# Set log level\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "    .options(header='True', inferSchema='True') \\\n",
    "    .load('round2_competition_data/eval_test/eval_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will remove the columns that are no longer useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_measurements = 6\n",
    "\n",
    "# Select columns to drop. We will keep timeAtServer and aircraft fields for visualization purposes\n",
    "cols = ['id', 'numMeasurements'] + ['sensor_{}'.format(i) for i in range(max_measurements)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will calculate the timestamp differences that are going to be used as additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of measurements to be taken into account while calculating differences\n",
    "n_meas_diff = 4\n",
    "\n",
    "for col_1 in range(1, n_meas_diff):\n",
    "    for col_2 in range(col_1):\n",
    "        df = df.withColumn('diff_{}_{}'.format(col_1, col_2), F.col('tmp_{}'.format(col_1)) - \\\n",
    "                           F.col('tmp_{}'.format(col_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          tmp_0|               tmp_1|               tmp_2|            diff_1_0|            diff_2_0|\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  5.770127167E9|2.662732089412679...| 5.770716371589668E9|2.085719372712679...|   589204.5896682739|\n",
      "|   9.68341093E8|-1.98891237046369...|-1.98906594110398...|-2.08574647976369...|-2.08590005040398...|\n",
      "|   9.82753933E8|-1.98800833742654...|                null|-2.08628373072654...|                null|\n",
      "|6.1095513667E10|8.225027432537793E10|6.140679142674698E10|2.115476065837793E10|3.1127775974697876E8|\n",
      "| 7.921691875E10|-1.04589263600445...| 7.90896239496978E10|-8.96758451100445...|-1.27294800302200...|\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('tmp_0', 'tmp_1', 'tmp_2', 'diff_1_0', 'diff_2_0').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next feature to extract is the mean latitude and longitude location of the sensors receiving the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'latitude_' in col]\n",
    "\n",
    "df = df.withColumn('mean_lat',\\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(F.col(col)) for col in cols])/ \\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(1) for col in cols])). \\\n",
    "     fillna(0, 'mean_lat')\n",
    "\n",
    "cols = [col for col in df.columns if 'longitude_' in col]\n",
    "\n",
    "df = df.withColumn('mean_lon',\\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(F.col(col)) for col in cols])/ \\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(1) for col in cols])). \\\n",
    "     fillna(0, 'mean_lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+------------------+\n",
      "|latitude_0|latitude_1|latitude_2|latitude_3|          mean_lat|\n",
      "+----------+----------+----------+----------+------------------+\n",
      "|   53.0433| 52.780922|  52.02494|  52.34244|        52.5479005|\n",
      "| 43.571663| 43.339207|  43.34309|   41.4643|42.929565000000004|\n",
      "| 46.762405| 46.761898|      null|      null|        46.7621515|\n",
      "|  52.47304|  50.93708|  52.53275|  52.53275| 51.90161383333333|\n",
      "| 50.883423|   50.8633|  51.32772|      null| 51.02481433333333|\n",
      "+----------+----------+----------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('latitude_0', 'latitude_1', 'latitude_2', 'latitude_3', 'mean_lat').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use the weighted mean of sensors coordinates as an additional feature. In this calculation, weights are going to be inverse values of timestamp measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'latitude_' in col]\n",
    "\n",
    "df = df.withColumn('w_mean_lat',\\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(F.col(col)*(1/F.col('tmp_{}'.format(i)))) \\\n",
    "          for i, col in enumerate(cols)])/ \\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(1/F.col('tmp_{}'.format(i))) \\\n",
    "          for i, col in enumerate(cols)])). \\\n",
    "     fillna(0, 'w_mean_lat')\n",
    "\n",
    "cols = [col for col in df.columns if 'longitude_' in col]\n",
    "\n",
    "df = df.withColumn('w_mean_lon',\\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(F.col(col)*(1/F.col('tmp_{}'.format(i)))) \\\n",
    "          for i, col in enumerate(cols)])/ \\\n",
    "     sum([F.when(F.col(col).isNull(), 0).otherwise(1/F.col('tmp_{}'.format(i))) \\\n",
    "          for i, col in enumerate(cols)])). \\\n",
    "     fillna(0, 'w_mean_lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+--------------------+-----------------+\n",
      "|latitude_0|latitude_1|          tmp_0|               tmp_1|       w_mean_lat|\n",
      "+----------+----------+---------------+--------------------+-----------------+\n",
      "|   53.0433| 52.780922|  5.770127167E9|2.662732089412679...|52.49118230290629|\n",
      "| 43.571663| 43.339207|   9.68341093E8|-1.98891237046369...|43.71810384249567|\n",
      "| 46.762405| 46.761898|   9.82753933E8|-1.98800833742654...|46.76243136648981|\n",
      "|  52.47304|  50.93708|6.1095513667E10|8.225027432537793E10|52.06661720099436|\n",
      "| 50.883423|   50.8633| 7.921691875E10|-1.04589263600445...|50.77621312581878|\n",
      "+----------+----------+---------------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('latitude_0', 'latitude_1', 'tmp_0', 'tmp_1', 'w_mean_lat').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, we will fill in missing values and save the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df \\\n",
    "    .fillna(-90, subset=[col for col in df.columns if 'latitude' in col]) \\\n",
    "    .fillna(-180, subset=[col for col in df.columns if 'longitude' in col]) \\\n",
    "    .fillna(-90, subset=[col for col in df.columns if 'mean_lat' in col]) \\\n",
    "    .fillna(-180, subset=[col for col in df.columns if 'mean_lon' in col]) \\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.save('round2_competition_data/tmp_evaltest/', format='csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir = os.listdir('round2_competition_data/tmp_evaltest/')\n",
    "\n",
    "if '_SUCCESS' in list_dir:\n",
    "    file_name = [name for name in list_dir if name.startswith('part')]\n",
    "    os.rename(os.path.join('round2_competition_data/tmp_evaltest', file_name[0]), \\\n",
    "              'round2_competition_data/tmp_evaltest/eval_test.csv')\n",
    "    os.replace('round2_competition_data/tmp_evaltest/eval_test.csv', 'round2_competition_data/eval_test/eval_test.csv')\n",
    "    \n",
    "    import shutil\n",
    "    shutil.rmtree('round2_competition_data/tmp_evaltest/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aircraft",
   "language": "python",
   "name": "aircraft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
